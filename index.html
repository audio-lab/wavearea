<!-- Main waveedit demo. See use-case. -->
<!DOCTYPE html>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>AU</title>

<link href="./style.css" rel="stylesheet"/>

<body>
  <div class="waveedit">
    <span :if="loading" style="position:absolute;">Loading...</span>

    <textarea class="wavearea wavefont" spellcheck="false"
      :onfocus-onblur="trackCaret" cols="500" :init="autosize(this)"
      :value="waveform"
    ></textarea>

    <audio class="playback" controls :src="`data:audio/mpeg;base64,${wavBase64}`"></audio>

    <!-- <div class="playback">
      <button class="record">
        <span :if="recording" title="Stop">x</span>
        <span :else title="Start recording">*</span>
      </button>
      <button class="play">
        <span :if="!playing" title="Play">></span>
        <span :else title="Pause">||</span>
      </button>
      <input class="volume" type="range" min="0" max="100" step="1" value="90" :value="volume" :oninput:onchange="e => volume.value = e.target.value" />
      <button class="download">_</button>
    </div> -->
  </div>

  <script type="importmap">
    {
      "imports": {
        "node-wav": "/source/lib/node-wav.js",
        "sprae": "/node_modules/sprae/sprae.min.js",
        "autosize": "/node_modules/@github/textarea-autosize/dist/index.js",
        "b64": "/source/lib/b64.js"
      }
    }
  </script>
  <script type="module">
    import sprae from 'sprae';
    import autosize from 'autosize';
    import wav from 'node-wav';
    import * as b64 from 'b64';

    const SAMPLE_RATE = 48000;
    const audioCtx = new OfflineAudioContext(2,SAMPLE_RATE*40,SAMPLE_RATE);

    let state = sprae(document.querySelector('.waveedit'), {
      // params
      loading: false,
      recording: false,
      playing: false,
      volume: 1,

      // currend audio buffer
      audioBuffer: null,

      // current displayed waveform text
      waveform: '',

      // current playable audio data
      wavBase64: '',

      // current selection
      selection: [0,0],

      // deps
      autosize,

      // reflect selection
      trackCaret(e) {
        const wavearea = e.target
        const track = () => console.log(state.selection = [wavearea.selectionStart, wavearea.selectionEnd])
        const evts = 'keypress mousedown touchstart input paste cut mousemove select selectstart change focus blur'.split(' ')
        evts.map(evt => wavearea.addEventListener(evt, track))
        return () => evts.map(evt => wavearea.removeEventListener(evt, track))
      }
    });

    loadAudio('./asset/Iskcon-manifest(enhanced).wav');

    // load audio source
    async function loadAudio(src) {
      state.loading = true;

      let resp = await fetch(src);
      if (!resp.ok) throw new Error(`HTTP error: status=${resp.status}`);

      console.time('to array buffer')
      let arrayBuffer = await resp.arrayBuffer();
      console.timeEnd('to array buffer')

      console.time('decode')
      let audioBuffer = await audioCtx.decodeAudioData(arrayBuffer);
      console.timeEnd('decode')

      state.audioBuffer = audioBuffer;

      console.time('to waveform string')
      state.waveform = toWaveform(audioBuffer);
      console.timeEnd('to waveform string')

      console.time('wav encode')
      const wav = toWav(audioBuffer);
      console.timeEnd('wav encode')

      console.time('base64')
      // FIXME: this guy takes 16ms
      state.wavBase64 = b64.encode(wav);
      console.timeEnd('base64')

      state.loading = false
    }

    function toWav(audioBuffer) {
      let channelData = audioBuffer.getChannelData(0)
      return wav.encode([channelData], { sampleRate: audioBuffer.sampleRate, float: false, bitDepth: 16 })
    }

    function toWaveform(audioBuffer) {
        if (!audioBuffer) return '';

        // map waveform to wavefont
        let channelData = audioBuffer.getChannelData(0), str = ''

        // approx. block size - close to chars length. Must be in sync with wavefont.
        let BLOCK_SIZE = 1024

        // normalize waveform before rendering
        // for every channel bring it to max-min amplitude range
        let max = 0
        for (let i = 0; i < channelData.length; i++) max = Math.max(Math.abs(channelData[i]), max)
        let amp = Math.max(1 / max, 1)
        for (let i = 0; i < channelData.length; i++) channelData[i] = Math.max(Math.min(amp * channelData[i], 1),-1);

        // TODO: weight waveform by audible spectrum

        // create wavefont string
        // amp coef brings up value a bit
        const VISUAL_AMP = 1//2.8
        for (let i = 0, nextBlock = BLOCK_SIZE; i < channelData.length;) {
          let ssum = 0, sum = 0

          // avg amp method - waveform is too small
          // for (; i < nextBlock; i++) sum += Math.abs(i > channelData.length ? 0 : channelData[i])
          // const avg = sum / BLOCK_SIZE
          // str += String.fromCharCode(0x0100 + Math.ceil(avg * 100))

          // rms method:
          // drawback: waveform is smaller than needed
          for (;i < nextBlock; i++) ssum += i > channelData.length ? 0 : channelData[i] ** 2
          const rms = Math.sqrt(ssum / BLOCK_SIZE)
          str += String.fromCharCode(0x0100 + Math.min(100, Math.ceil(rms * 100 * VISUAL_AMP)))

          nextBlock += BLOCK_SIZE
        }

        return str
      }
  </script>
</body>