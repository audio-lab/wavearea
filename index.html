<!-- Main waveedit demo. See use-case. -->
<!DOCTYPE html>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>AU</title>

<link href="./style.css" rel="stylesheet"/>

<body>
  <div class="waveedit">
    <span :if="loading" style="position:absolute;">Loading...</span>

    <div class="we-container">
      <div class="we-sizer wavefont" :text="waveform"></div>
      <textarea :ref="wavearea"
        class="we-wavearea wavefont" spellcheck="false" cols="540"
        :onfocus-onblur="trackCaret"
        :value="waveform"
      ></textarea>
    </div>

    <audio :ref="audio" class="we-playback" controls :src="wavURL" :onplay-onpause="play"></audio>

    <!-- <div class="playback">
      <button class="record">
        <span :if="recording" title="Stop">x</span>
        <span :else title="Start recording">*</span>
      </button>
      <button class="play">
        <span :if="!playing" title="Play">></span>
        <span :else title="Pause">||</span>
      </button>
      <input class="volume" type="range" min="0" max="100" step="1" value="90" :value="volume" :oninput:onchange="e => volume.value = e.target.value" />
      <button class="download">_</button>
    </div> -->
  </div>

  <script type="importmap">
    {
      "imports": {
        "node-wav": "/source/lib/node-wav.js",
        "sprae": "/node_modules/sprae/sprae.js",
        "autosize": "/node_modules/@github/textarea-autosize/dist/index.js",
        "b64": "/source/lib/b64.js"
      }
    }
  </script>
  <script type="module">
    import sprae from 'sprae';
    import wav from 'node-wav';
    import * as b64 from 'b64';

    const SAMPLE_RATE = 48000;
    // approx. block size - close to chars length. Must be in sync with wavefont.
    const BLOCK_SIZE = 1024
    const audioCtx = new OfflineAudioContext(2,SAMPLE_RATE*40,SAMPLE_RATE);

    let state = sprae(document.querySelector('.waveedit'), {

      // params
      loading: false,
      recording: false,
      playing: false,
      volume: 1,

      // currend audio buffer
      audioBuffer: null,

      // current displayed waveform text
      waveform: '',

      // current playable audio data
      wavURL: '',

      // selection -> audio timeline
      trackCaret(e) {
        const {wavearea, audio} = state
        const track = (e) => {
          if (!state.playing) audio.currentTime = wavearea.selectionStart * BLOCK_SIZE / SAMPLE_RATE
        }
        const evts = 'keypress keydown mousedown click touchstart input select selectstart paste cut change'.split(' ')
        evts.map(evt => wavearea.addEventListener(evt, track))
        return () => evts.map(evt => wavearea.removeEventListener(evt, track))
      },

      play (e) {
        let {wavearea, audio} = state
        state.playing = true;
        const startTime = audio.currentTime
        const startFrame = Math.floor(startTime * SAMPLE_RATE / BLOCK_SIZE)
        const endFrame = (wavearea.selectionEnd && wavearea.selectionEnd !== wavearea.selectionStart) ? wavearea.selectionEnd : wavearea.value.length
        let animId

        const syncCaret = () => {
          const framesPlayed = Math.floor((audio.currentTime - startTime) * SAMPLE_RATE / BLOCK_SIZE)
          const currentFrame = startFrame + framesPlayed;
          wavearea.selectionStart = wavearea.selectionEnd = currentFrame
          if (currentFrame >= endFrame) {
            audio.pause();
          }
          else animId = requestAnimationFrame(syncCaret)
        }
        syncCaret()

        wavearea.focus();

        return () => {
          state.playing = false
          cancelAnimationFrame(animId), animId = null

          // return selection if there was any
          console.log('end')
          if (startFrame !== endFrame) wavearea.selectionStart = startFrame, wavearea.selectionEnd = endFrame
        }
      }
    });

    loadAudio('./asset/Iskcon-manifest(enhanced).wav');

    // load audio source
    async function loadAudio(src) {
      state.loading = true;

      let resp = await fetch(src);
      if (!resp.ok) throw new Error(`HTTP error: status=${resp.status}`);

      console.time('to array buffer')
      let arrayBuffer = await resp.arrayBuffer();
      console.timeEnd('to array buffer')

      console.time('decode')
      let audioBuffer = await audioCtx.decodeAudioData(arrayBuffer);
      console.timeEnd('decode')

      state.audioBuffer = audioBuffer;

      console.time('to waveform string')
      state.waveform = toWaveform(audioBuffer);
      console.timeEnd('to waveform string')

      console.time('wav encode')
      const wav = toWav(audioBuffer);
      console.timeEnd('wav encode')

      console.time('wav url')
      const blob = new Blob([wav], { type: "audio/wav" });
      state.wavURL = URL.createObjectURL(blob);
      // audio.onload = function (e) { windowURL.revokeObjectURL(this.src); }
      console.timeEnd('wav url')

      // NOTE: this guy takes 16s
      // console.time('base64')
      // state.wavURL = `data:audio/mpeg;base64,` + b64.encode(wav);
      // console.timeEnd('base64')

      state.loading = false
    }

    function toWav(audioBuffer) {
      let channelData = audioBuffer.getChannelData(0)
      return wav.encode([channelData], { sampleRate: audioBuffer.sampleRate, float: false, bitDepth: 16 })
    }

    function toWaveform(audioBuffer) {
        if (!audioBuffer) return '';

        // map waveform to wavefont
        let channelData = audioBuffer.getChannelData(0), str = ''

        // normalize waveform before rendering
        // for every channel bring it to max-min amplitude range
        let max = 0
        for (let i = 0; i < channelData.length; i++) max = Math.max(Math.abs(channelData[i]), max)
        let amp = Math.max(1 / max, 1)
        for (let i = 0; i < channelData.length; i++) channelData[i] = Math.max(Math.min(amp * channelData[i], 1),-1);

        // TODO: weight waveform by audible spectrum

        // create wavefont string
        // amp coef brings up value a bit
        const VISUAL_AMP = 2
        for (let i = 0, nextBlock = BLOCK_SIZE; i < channelData.length;) {
          let ssum = 0, sum = 0

          // avg amp method - waveform is too small
          // for (; i < nextBlock; i++) sum += Math.abs(i > channelData.length ? 0 : channelData[i])
          // const avg = sum / BLOCK_SIZE
          // str += String.fromCharCode(0x0100 + Math.ceil(avg * 100))

          // rms method:
          // drawback: waveform is smaller than needed
          for (;i < nextBlock; i++) ssum += i > channelData.length ? 0 : channelData[i] ** 2
          const rms = Math.sqrt(ssum / BLOCK_SIZE)
          str += String.fromCharCode(0x0100 + Math.min(100, Math.ceil(rms * 100 * VISUAL_AMP)))

          nextBlock += BLOCK_SIZE
        }

        return str
      }
  </script>
</body>