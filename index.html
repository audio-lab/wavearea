<!-- Main waveedit demo. See use-case. -->
<!DOCTYPE html>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>AU</title>

<link href="./style.css" rel="stylesheet"/>

<body>
  <div class="waveedit">
    <span :if="loading" style="position:absolute;">Loading...</span>

    <textarea class="wavearea wavefont" spellcheck="false"
      :onfocus-onblur="trackCaret" cols="500" :init="autosize(this)"
      :value="waveform"
    ></textarea>

    <div class="playback">
      <button class="record">
        <span :if="recording" title="Stop">x</span>
        <span :else title="Start recording">*</span>
      </button>
      <button class="play">
        <span :if="!playing" title="Play">></span>
        <span :else title="Pause">||</span>
      </button>
      <input class="volume" type="range" min="0" max="100" step="1" value="90" :value="volume" :oninput:onchange="e => volume.value = e.target.value" />
      <button class="download">_</button>
    </div>
  </div>

  <script type="importmap">
    {
      "imports": {
        "sprae": "/node_modules/sprae/sprae.min.js",
        "autosize": "/node_modules/@github/textarea-autosize/dist/index.js"
      }
    }
  </script>
  <script type="module">
    import sprae from 'sprae';
    import autosize from 'autosize';

    let state = sprae(document.querySelector('.waveedit'), {
      // params
      loading: false,
      recording: false,
      playing: false,
      volume: 1,

      // currend audio buffer
      audioBuffer: null,

      // get wavefont string from audio buffer
      // FIXME: instead of recalculating waveform in complete, we can do fragments of it
      get waveform() {
        let { audioBuffer } = this;
        if (!audioBuffer) return '';

        // audio.value = new Audio
        // audio.value.src = `data:audio/mpeg;base64,${base64}`

        // // obtain waveform from audio input
        // let wavData = b64.decode(response.output.target_wave.content);
        // let audioBuffer = wav.decode(wavData);

        // map waveform to wavefont
        let channelData = audioBuffer.getChannelData(0), str = ''

        // approx. block size - close to chars length. Must be in sync with wavefont.
        let BLOCK_SIZE = 1024

        // normalize waveform before rendering
        // for every channel bring it to max-min amplitude range
        let max = 0
        for (let i = 0; i < channelData.length; i++) max = Math.max(Math.abs(channelData[i]), max)
        let amp = Math.max(1 / max, 1)
        for (let i = 0; i < channelData.length; i++) channelData[i] = Math.max(Math.min(amp * channelData[i], 1),-1);

        // TODO: weight waveform by audible spectrum

        // create wavefont string
        // amp coef brings up value a bit
        const VISUAL_AMP = 1//2.8
        for (let i = 0, nextBlock = BLOCK_SIZE; i < channelData.length;) {
          let ssum = 0, sum = 0

          // avg amp method - waveform is too small
          // for (; i < nextBlock; i++) sum += Math.abs(i > channelData.length ? 0 : channelData[i])
          // const avg = sum / BLOCK_SIZE
          // str += String.fromCharCode(0x0100 + Math.ceil(avg * 100))

          // rms method:
          // drawback: waveform is smaller than needed
          for (;i < nextBlock; i++) ssum += i > channelData.length ? 0 : channelData[i] ** 2
          const rms = Math.sqrt(ssum / BLOCK_SIZE)
          str += String.fromCharCode(0x0100 + Math.min(100, Math.ceil(rms * 100 * VISUAL_AMP)))

          nextBlock += BLOCK_SIZE
        }

        return str
      },

      // current selection
      selection: [0,0],

      // deps
      autosize,

      // reflect selection
      trackCaret(e) {
        const wavearea = e.target
        const track = () => console.log(state.selection = [wavearea.selectionStart, wavearea.selectionEnd])
        const evts = 'keypress mousedown touchstart input paste cut mousemove select selectstart change focus blur'.split(' ')
        evts.map(evt => wavearea.addEventListener(evt, track))
        return () => evts.map(evt => wavearea.removeEventListener(evt, track))
      }
    });

    // load audio source
    const sr = 48000;
    const audioCtx = new OfflineAudioContext(2,sr*40,sr);
    const source = audioCtx.createBufferSource();
    async function loadAudio(src) {
      state.loading = true;

      let resp = await fetch(src);
      if (!resp.ok) throw new Error(`HTTP error: status=${resp.status}`);

      let arrayBuffer = await resp.arrayBuffer();

      let audioBuffer = await audioCtx.decodeAudioData(arrayBuffer);

      console.log('Loaded audio:', audioBuffer)

      state.audioBuffer = audioBuffer;
      state.loading = false
    }

    loadAudio('./asset/Iskcon-manifest(enhanced).wav');
  </script>
</body>