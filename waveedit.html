<!DOCTYPE html>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Audio textarea</title>

<link rel="stylesheet" href="https://unpkg.com/modern-normalize@1.0.0/modern-normalize.css" rel="preload"/>

<style id="base-style">
  /* flex font size */
  html {font-size: 100%;}

  @media screen and (min-width: 320px) {
    html {
      font-size: calc(12px + 6 * ((100vw - 320px) / 680));
    }
  }
  @media screen and (min-width: 1000px) {
    html {
      font-size: 18px;
    }
  }

  :root {
    font-size: 100%/1.5;
  }

  a {
    color: black;
    text-decoration-color: rgba(0,0,0,.108);
    text-underline-offset: .108em;
    text-decoration-thickness: .108ch;
  }
  @font-face {
    font-family: wavefont;
    src: url(./asset/wavefont.woff2) format('woff2');
  }
  @font-face {
    font-family: blank;
     src: url(./asset/AdobeBlack2VF.ttf.woff2);
     /*src: url(./asset/AdobeBlank2VF.ttf.woff2); */
    /*src: url(data:application/x-font-woff;charset=utf-8;base64,d09GMgABAAAAAARMABMAAAAAC1AAAAPjAAEAxQAAAAAAAAAAAAAAAAAAAAAAAAAAGUYcID9IVkFSVAZgP1NUQVQkP1ZWQVJjAIIAL0YKWFwwLgE2AiQDCAsGAAQgBYsyBzEXJBgIGwEKEcXkJfmqgCdD4yWAULaeeBovVzstIc6riunXpnmtXivg+BLWsFA1x8PTXP+eO5PNAn8AUCwJsYCgqxxZ1JUELrLsXkOo3TUpDjbRB8Tvo61HSFe6NVBVO1SvlxDEvYxsxE4DfNN8ImIOJ0gqtv/9fq0+Wat/NsTds46FRuqU8lf0gse1iqY3dLfkGRqhqiTVConpREoxCY1FPHelp1Ny+uwFWpZYoBA7dh04oaUEhFLUFDri7o2bj2BaFYGOOeZ1vLhvdQ0IMAUABHoC6yWZLbYAgJ9NX06XhIBcaa5iDdL76Qz2k7njkrV+ci1cx5uLNbeOtx22hbrOrMaqxrO/9QL9NwVgAUJoSZgClkjP3HjyTmDP7j0nIoQAM3AGAJfCk0F+cI8EIeugpw/+AUwGvq0R/IaJbxBM/EE9gRAIQEJCRkaBAg00UKJEE0200EIbbXTQQRdd9NBDH30MMMAQQ4wwEuEmSaYkBnnYDCBXEDnpwW9EJK5WZJBAgQZGmA0oQIMiXw91sjku790e3LzZfHZ461Z5+/ozFVTN2diLFz9/ql67cl8k+nvMWO4OBBKYtXsY6LwaespXbYFXt+TqtTcIhK83bvTx5eGGf1s5V/D9qt/p9najlt/Mj6KUQFCxsYrB4sZY4VoloVbYkpHGKGGx3RT/yaJo4wSfCEucQDLwLLLV3u5asKHhhk9QmpVZaOnEerTNyqaunQW61ucM+umj+BAD6xtRwIJe7SdfPJ0j6BTPIkzxelO3WVhf//c2jpwWnwkGXVHJ7/FoDWDAQVkQ+OBTFKZJu8lXljDZnk7YqITmExH/y0MxUyoCDOBqChwdIU8mZhKKCJ2upGVgbGinpSoKOgThuVdIkAJUCkD1UYqNlj3J5kSRrqElYYogo7sLvSE3eCVefdEJa/SRA1H0BWVMIMAKSoG1TMqBSbtr5Q+DNGe+gASmqJQCTiiX8mISEDDtHgvYUEpCDjCuCZD0oQJ1YQ3sjHRPlXdfK+E/rSY28Bg4cI6cV00RDZaMcjGklsyXggUDJ2BRVwCGvwLAfxa/WTib27k4LwoOHB0NbJMLE/HNdo7AyM7W2AINfIZwPg2I0KNAtGALqE+jIEEkfiTfWAAkgSiiBZJkLDgSCXf6EaZ2NnDRspAUq7MFXOYSaLDGnozJK4dkPCmTRSmRKSxxWiDAMFMxKVLnoZ7iPA0oLgj+UBlRkrmlg3DbW9ieSDMnJbu4KqNIxL1kjISZ9GjJ5+t2TALq0U3AcYLmZeFeX9Ww6+F30lD/+kXetcg6ZJg3EalzO/5jvn7dbo3cSO6f/4dc8dJzzBkJMwsAAAA=) format('woff2');*/
  }

  .wavefont {
    font-family: wavefont, blank;
    font-size: 10.8rem;
    letter-spacing: .0108ex;
    --wdth: 17.28;
    font-variation-settings: 'wdth' var(--wdth), 'algn' 0.5, 'radi' 50;
  }
  #wavearea {
    resize: both;
    width: 100%;
    outline: none;
    border: none;
    padding: 0;
    line-height: 1;
    background-size: 100vw calc(1em);
    background-attachment: local;
    background-position: 0 .5em;
    background-image: linear-gradient(to bottom, rgb(230, 245, 255) 1px, transparent 1px);
  }
</style>

<input id="input-file" type="file" capture="user" accept="audio/*">
<!-- <img src="../asset/upload.svg"></input> -->
<button id="play"><img src="../asset/play.svg"></button>
<!-- <button><img src="../asset/download.svg"></button> -->
<!-- <button><img src="../asset/settings.svg"></button> -->
<textarea id="wavearea" class="wavefont" spellcheck="false" autofocus wavearea></textarea>


<script type="module">
import * as au from './source/lib/audio-util.js'

const inputFile = document.querySelector('#input-file')
const wavearea = document.querySelector('#wavearea')
const playButton = document.querySelector('#play')


let audioBuffer, audioContext = new AudioContext()
// abl is like audio-track. No need to store multiple chunks, just display audiobuffer
const frameSize = 512   // ~ 50fps
// track caret - alternative to tracking multiple various events
let fromFrame, toFrame

document.addEventListener('click', e => {
  if (audioContext.state !== 'running') audioContext.resume()
})

inputFile.onchange = async e => {
  const fileList = inputFile.files

  let arrayBuf = await readAudio(fileList[0])
  audioBuffer = await decodeAudio(arrayBuf)

  drawData(audioBuffer)
}

// must come before tracking caret because we need prev caret state and input already updates content
wavearea.addEventListener('input', e => {
  // TODO: in case we switch to contenteditable, it's possible to use this method
  // console.log(e.getTargetRanges())
  if (e.inputType === 'deleteContentBackward') {
    console.log('deleting', fromFrame, toFrame)
    audioBuffer = au.remove(audioBuffer, fromFrame*frameSize, toFrame*frameSize)
  }
})

// document.onselectionchange
function trackCaret (e) {
  if (document.activeElement !== wavearea) return
  fromFrame = wavearea.selectionStart, toFrame = wavearea.selectionEnd
}
wavearea.addEventListener('keypress', trackCaret); // Every character written
wavearea.addEventListener('mousedown', trackCaret); // Click down
wavearea.addEventListener('touchstart', trackCaret); // Mobile
wavearea.addEventListener('input', trackCaret); // Other input events
wavearea.addEventListener('paste', trackCaret); // Clipboard actions
wavearea.addEventListener('cut', trackCaret);
wavearea.addEventListener('mousemove', trackCaret); // Selection, dragging text
wavearea.addEventListener('select', trackCaret); // Some browsers support this event
wavearea.addEventListener('selectstart', trackCaret); // Some browsers support this event


playButton.onclick = async e => {
  wavearea.focus()
  wavearea.selectionStart = wavearea.selectionEnd = wavearea.selectionStart || 0; // reselection on focus bug

  const ended = await playAudio(fromFrame, toFrame)
}

async function playAudio(startFrame, endFrame) {
  if (startFrame === wavearea.value.length) startFrame = 0;
  if (startFrame === endFrame) endFrame = wavearea.value.length;

  const startTime = audioContext.currentTime

  // sync caret
  updateCaret()
  function updateCaret () {
    const framesPlayed = Math.floor((audioContext.currentTime - startTime) * audioContext.sampleRate / frameSize)
    wavearea.selectionStart = wavearea.selectionEnd = Math.min(startFrame + framesPlayed, endFrame)
    if (startFrame + framesPlayed >= endFrame) return
    requestAnimationFrame(updateCaret)
  }

  // TODO: parallelize with context resume?
  const buffer = au.slice(audioBuffer, startFrame*frameSize, endFrame*frameSize)
  const sampleSource = audioContext.createBufferSource()
  sampleSource.buffer = buffer
  sampleSource.connect(audioContext.destination)

  // await audioContext.resume();
  sampleSource.onended = e => {
    sampleSource.disconnect()
    // setTimeout(() => audioContext.suspend(), 50)
  }

  sampleSource.start(startTime);
  // round startTime to sample to avoid interpolation
  // NOTE: can produce ring effect, since not perfectly aligned in startTime, interval varies
  // sampleSource.start(Math.floor(startTime * audioContext.sampleRate) / audioContext.sampleRate);
}



// render abuffer bars
function drawData(abuf) {
  let data = abuf.getChannelData(0)
  let waveStr = ''

  // for calibrating to unit gauss can use this:
  // for (let i = 0; i < frameSize * 8; i++) data[i] = gaussRandom()

  // TODO: try average absolute deviation vs std deviation
  // see https://en.wikipedia.org/wiki/Statistical_dispersion
  for (let offset = 0; offset < data.length; offset += frameSize) {
    let sum = 0, sum2 = 0
    for (let i = 0; i < frameSize; i++) {
      let x = data[offset + i] || 0
      sum += x
      sum2 += x*x
    }
    let mean = sum / frameSize
    // https://www.mun.ca/biology/scarr/Simplified_calculation_of_variance.html
    let sdev = Math.sqrt(sum2 / frameSize - mean*mean)
    let value = Math.ceil(sdev * 100)
    waveStr += value ? String.fromCharCode(0x100 + value) : ' '
  }

  wavearea.value = waveStr
}

function readAudio(file) {
  // Check if the file is an image.
  if (file.type && !file.type.startsWith('audio/')) {
    console.log('File is not an audio.', file.type, file);
    return;
  }

  return new Promise((y,n) => {
    const reader = new FileReader();
    reader.addEventListener('load', (event) => {
      y(event.target.result);
    });
    reader.readAsArrayBuffer(file);
  })
}

function decodeAudio(buf) {
  return audioContext.decodeAudioData(buf)
}


function gaussRandom() {
  return Math.sqrt(-2.0 * Math.log(Math.random())) * Math.cos(2.0 * Math.PI * Math.random())
}


// document.querySelectorAll('[wavearea]').forEach(el => new Wavearea(el))
</script>

<p align="center" style="position: absolute; bottom: 0; right: 0;">ðŸ•‰<p>
